{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny Training Trial\n",
    "This notebook is to support the [Tiny Training Trial](https://w.amazon.com/bin/view/MLSciences/Community/ML_Challenge/TinyTraining/). The associated Leaderboard is available [here](https://leaderboard.corp.amazon.com/tasks/292).\n",
    "\n",
    "## Loading the Data into Eider:\n",
    "Since we got some people asking about best ways to import into Eider, I thought we'd go one step further and make it trivial to import!  Below is a snippet for loading and and taking a look at the dataset via S3 below. It's highly recommended to use the below method to avoid a needless local import. \n",
    "\n",
    "First, let's make sure we have our credentials set to ```ml-eider-shared-1```, and then load them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download Training Data and Test Features ###\n",
    "\n",
    "import pandas as pd\n",
    "eider.s3.download('s3://eider-datasets/mlu/projects/DontOverFitChallenge/TTT_train.csv', '/tmp/TTT_train.csv')\n",
    "eider.s3.download('s3://eider-datasets/mlu/projects/DontOverFitChallenge/TTT_test_features.csv', '/tmp/TTT_test_features.csv')\n",
    "\n",
    "train = pd.read_csv('/tmp/TTT_train.csv')\n",
    "test = pd.read_csv('/tmp/TTT_test_features.csv',index_col = 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is the data like?\n",
    "#train.describe()\n",
    "'''\n",
    "is_class0 = train['label'] == 0\n",
    "is_class8 = train['label'] == 8\n",
    "is_class9 = train['label'] == 9\n",
    "\n",
    "is_class1 = train['label'] == 1\n",
    "is_class2 = train['label'] == 2\n",
    "is_class3 = train['label'] == 3\n",
    "is_class4 = train['label'] == 4\n",
    "is_class5 = train['label'] == 5\n",
    "is_class6 = train['label'] == 6\n",
    "is_class7 = train['label'] == 7\n",
    "\n",
    "train_class0 = train[is_class0]\n",
    "train_class8 = train[is_class8]\n",
    "train_class9 = train[is_class9]\n",
    "dataframes089 = [train_class0, train_class8, train_class9]\n",
    "\n",
    "train_class1 = train[is_class1]\n",
    "train_class2 = train[is_class2]\n",
    "train_class3 = train[is_class3]\n",
    "train_class4 = train[is_class4]\n",
    "train_class5 = train[is_class5]\n",
    "train_class6 = train[is_class6]\n",
    "train_class7 = train[is_class7]\n",
    "dataframes_remaining = [train_class1, train_class2, train_class3, train_class4, train_class5, train_class6, train_class7]\n",
    "\n",
    "#selective_train = pd.concat(dataframes089)\n",
    "selective_train = pd.concat(dataframes_remaining)\n",
    "\n",
    "print selective_train.shape\n",
    "print selective_train.head(4)\n",
    "selective_train['label'].hist()\n",
    "'''\n",
    "train['label'].hist()\n",
    "print train.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print train.label.value_counts()\n",
    "print selective_train.label.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#split data and labels\n",
    "Features, labels = train.drop([\"label\"], axis = 1), train[\"label\"]\n",
    "print(\"Features-labels shape\", Features.shape, labels.shape, test.shape)\n",
    "Features_train, Features_test, labels_train, labels_test = train_test_split(Features, labels, test_size = 0.2, random_state = 54321)\n",
    "print(\"train-test shape\", Features_train.shape, Features_test.shape, labels_train.shape, labels_test.shape)\n",
    "\n",
    "'''\n",
    "#split selective train that is focussed on class 0, 8 and 9\n",
    "selective_Features, selective_labels = selective_train.drop([\"label\"], axis = 1), selective_train[\"label\"]\n",
    "selective_Features_train, selective_Features_test, selective_labels_train, selective_labels_test = train_test_split(selective_Features, selective_labels, test_size = 0.2, random_state = 42)\n",
    "print(\"selective-Features-labels shape\", selective_Features.shape, selective_labels.shape, test.shape)\n",
    "print(\"selective-train-test shape\", selective_Features_train.shape, selective_Features_test.shape, selective_labels_train.shape, selective_labels_test.shape)\n",
    "\n",
    "Features = selective_Features\n",
    "labels = selective_labels\n",
    "\n",
    "Features_train = selective_Features_train\n",
    "Features_test = selective_Features_test\n",
    "labels_train = selective_labels_train\n",
    "labels_test = selective_labels_test\n",
    "print(\"Features-labels shape\", Features.shape, labels.shape, test.shape)\n",
    "print(\"train-test shape\", Features_train.shape, Features_test.shape, labels_train.shape, labels_test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretty print best scores for hypertuning\n",
    "def report_best_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "def combinations_on_off(num_classifiers):\n",
    "    return [[int(x) for x in list(\"{0:0b}\".format(i).zfill(num_classifiers))]\n",
    "           for i in np.arange(1, 2 ** num_classifiers)]\n",
    "    \n",
    "\n",
    "def Stacking(model,train,y,test,n_fold):\n",
    "  folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n",
    "  #test_pred=np.empty((test.shape[0],1),float)\n",
    "  test_pred=np.empty((0,1),float)\n",
    "  train_pred=np.empty((0,1),float)\n",
    "  for train_indices,val_indices in folds.split(train,y.values):\n",
    "    x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n",
    "    y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n",
    "    model.fit(X=x_train,y=y_train)\n",
    "    train_pred=np.append(train_pred,model.predict(x_val))\n",
    "    \n",
    "  test_pred=np.append(test_pred,model.predict(test))\n",
    "  return test_pred.reshape(-1,1),train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#stacking ensemble\n",
    "rf = RandomForestClassifier(n_estimators=500, max_features=26, min_samples_split=4, bootstrap=False, criterion=\"gini\", max_depth=None)\n",
    "test_pred_rf ,train_pred_rf=Stacking(model=rf,n_fold=10, train=Features_train,test=Features_test,y=labels_train)\n",
    "train_pred_rf = pd.DataFrame(train_pred_rf)\n",
    "test_pred_rf = pd.DataFrame(test_pred_rf)\n",
    "\n",
    "svc = SVC(kernel='linear', C=2.2, gamma=1, probability=True)\n",
    "test_pred_svc ,train_pred_svc=Stacking(model=svc,n_fold=10, train=Features_train,test=Features_test,y=labels_train)\n",
    "train_pred_svc = pd.DataFrame(train_pred_svc)\n",
    "test_pred_svc = pd.DataFrame(test_pred_svc)\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=None, random_state=42)\n",
    "test_pred_gb ,train_pred_gb=Stacking(model=gb,n_fold=10, train=Features_train,test=Features_test,y=labels_train)\n",
    "train_pred_gb = pd.DataFrame(train_pred_gb)\n",
    "test_pred_gb = pd.DataFrame(test_pred_gb)\n",
    "\n",
    "xgb = XGBClassifier(objective=\"binary:logistic\", colsample_bytree=0.9161548184174394, learning_rate=0.074321727571868, n_estimators=102, subsample=0.9377762690534515, max_depth=4, gamma=0.031170681255620725, scale_pos_weight=3)\n",
    "test_pred_xgb ,train_pred_xgb=Stacking(model=xgb,n_fold=10, train=Features_train,test=Features_test,y=labels_train)\n",
    "train_pred_xgb = pd.DataFrame(train_pred_xgb)\n",
    "test_pred_xgb = pd.DataFrame(test_pred_xgb)\n",
    "\n",
    "df = pd.concat([train_pred_rf, train_pred_svc, train_pred_gb, train_pred_gb], axis=1)\n",
    "df_test = pd.concat([test_pred_rf, test_pred_svc, test_pred_gb, test_pred_gb], axis=1)\n",
    "\n",
    "print df.head()\n",
    "print Features_train.head()\n",
    "\n",
    "df.columns = [\"rf_pred\", \"svc_pred\", \"gb_pred\", \"xgb_pred\"]\n",
    "df_test.columns = [\"rf_pred\", \"svc_pred\", \"gb_pred\", \"xgb_pred\"]\n",
    "data = pd.concat([df, Features_train.reset_index().drop([\"index\"], axis = 1)], axis = 1)\n",
    "data_test = pd.concat([df_test, Features_test.reset_index().drop([\"index\"], axis = 1)], axis = 1)\n",
    "print data.head(n=50)\n",
    "\n",
    "#model = LogisticRegression(random_state=42)\n",
    "#model = RandomForestClassifier(n_estimators=10, max_features=26, min_samples_split=4, bootstrap=False, criterion=\"gini\", max_depth=None)\n",
    "#model = SVC(kernel='linear', C=2.2, gamma=1, probability=True)\n",
    "#model = XGBClassifier(objective=\"binary:logistic\", colsample_bytree=0.9161548184174394, learning_rate=0.074321727571868, n_estimators=102, subsample=0.9377762690534515, max_depth=4, gamma=0.031170681255620725, scale_pos_weight=3)\n",
    "model = GradientBoostingClassifier(n_estimators=102, learning_rate=0.074321727571868, max_depth=4, random_state=42)\n",
    "model.fit(data,labels_train)\n",
    "labels_pred = model.predict(data_test)\n",
    "\n",
    "print(accuracy_score(labels_test, labels_pred))\n",
    "print confusion_matrix(labels_test, labels_pred)\n",
    "\n",
    "print stats.describe(cross_val_score(model, Features, labels, cv=5, scoring='accuracy'))\n",
    "\n",
    "print model.score(data_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extreme boost classifier \n",
    "xgb = XGBClassifier(objective=\"binary:logistic\", colsample_bytree=0.9161548184174394, learning_rate=0.074321727571868, n_estimators=102, subsample=0.9377762690534515, max_depth=4, gamma=0.031170681255620725, scale_pos_weight=3)\n",
    "#xgb = XGBClassifier(objective=\"binary:logistic\")\n",
    "'''\n",
    "params = {\n",
    "    \"colsample_bytree\": uniform(0.7, 0.3),\n",
    "    \"gamma\": uniform(0, 0.5),\n",
    "    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
    "    \"max_depth\": randint(2, 6), # default 3\n",
    "    \"n_estimators\": randint(100, 150), # default 100\n",
    "    \"subsample\": uniform(0.6, 0.4),\n",
    "    \"min_child_weight\": [5,6],\n",
    "    \"scale_pos_weight\": [1,2,3,4]\n",
    "}\n",
    "print \"searching....\"\n",
    "search = RandomizedSearchCV(xgb, param_distributions=params, random_state=42, n_iter=200, cv=5, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "print \"fitting....\"\n",
    "search.fit(Features, labels)\n",
    "print \"reporting....\"\n",
    "report_best_scores(search.cv_results_, 1)\n",
    "'''\n",
    "xgb.fit(Features_train, labels_train)\n",
    "labels_pred = xgb.predict(Features_test)\n",
    "print(accuracy_score(labels_test, labels_pred))\n",
    "plt.matshow(confusion_matrix(labels_test, labels_pred))\n",
    "plt.title('Confusion matrix - XGBClassifier')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "print confusion_matrix(labels_test, labels_pred)\n",
    "\n",
    "stats.describe(cross_val_score(xgb, Features, labels, cv=5, scoring='accuracy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "mNB = MultinomialNB(alpha=0.22, fit_prior=True, class_prior=None)\n",
    "mNB.fit(Features_train, labels_train)\n",
    "labels_pred = mNB.predict(Features_test)\n",
    "\n",
    "print(accuracy_score(labels_test, labels_pred))\n",
    "print confusion_matrix(labels_test, labels_pred)\n",
    "stats.describe(cross_val_score(mNB, Features, labels, cv=5, scoring='accuracy'))\n",
    "log_loss(labels_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM Classifier\n",
    "\n",
    "#svm = SVC(kernel='linear', C=2.21, gamma=1)\n",
    "svm = SVC(kernel='linear', C=2.2, gamma=0.001)\n",
    "'''\n",
    "params = {\n",
    "        'C': randint(1,10),\n",
    "        'gamma': [0.0001, 0.001, 0.01, 1, 10],\n",
    "        'kernel': ['linear','rbf']\n",
    "    }\n",
    "search = RandomizedSearchCV(svm, param_distributions=params, random_state=42, n_iter=200, cv=5, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "print \"fitting....\"\n",
    "search.fit(Features, labels)\n",
    "print \"reporting....\"\n",
    "report_best_scores(search.cv_results_, 1)\n",
    "'''\n",
    "svm.fit(Features_train, labels_train)\n",
    "labels_pred = svm.predict(Features_test)\n",
    "print(accuracy_score(labels_test, labels_pred))\n",
    "print confusion_matrix(labels_test, labels_pred)\n",
    "stats.describe(cross_val_score(svm, Features, labels, cv=5, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500, max_features=25, min_samples_split=9, bootstrap=False, criterion=\"gini\", max_depth=None)\n",
    "'''rf = RandomForestClassifier(n_estimators=500)\n",
    "params = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 30),\n",
    "              \"min_samples_split\": randint(2, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "print \"searching....\"\n",
    "search = RandomizedSearchCV(rf, param_distributions=params, random_state=42, n_iter=200, cv=5, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "print \"fitting....\"\n",
    "search.fit(Features, labels)\n",
    "print \"reporting....\"\n",
    "report_best_scores(search.cv_results_, 1)\n",
    "\n",
    "'''\n",
    "rf.fit(Features_train, labels_train)\n",
    "labels_pred = rf.predict(Features_test)\n",
    "print(accuracy_score(labels_test, labels_pred))\n",
    "plt.matshow(confusion_matrix(labels_test, labels_pred))\n",
    "plt.title('Confusion matrix - Voting Classifier')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "print confusion_matrix(labels_test, labels_pred)\n",
    "\t\n",
    "stats.describe(cross_val_score(rf, Features, labels, cv=5, scoring='accuracy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest + SVM ensemble\n",
    "rf = RandomForestClassifier(n_estimators=500, max_features=26, min_samples_split=4, bootstrap=False, criterion=\"gini\", max_depth=None)\n",
    "svc = SVC(kernel='linear', C=2.2, gamma=1, probability=True)\n",
    "#xgb = XGBClassifier(objective=\"binary:logistic\", colsample_bytree=0.9514986114133412, learning_rate=0.15444585070129954, n_estimators=147, subsample=0.9458889505020213, max_depth=2, gamma=0.23434657989748514, scale_pos_weight=3)\n",
    "#rf = RandomForestClassifier(n_estimators=500, max_features=25, min_samples_split=9, bootstrap=False, criterion=\"gini\", max_depth=None)\n",
    "#svc = SVC(kernel='linear', C=2.2, gamma=0.001, probability=True)\n",
    "xgb = XGBClassifier(objective=\"binary:logistic\", colsample_bytree=0.9161548184174394, learning_rate=0.074321727571868, n_estimators=102, subsample=0.9377762690534515, max_depth=4, gamma=0.031170681255620725, scale_pos_weight=3)\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=None, random_state=42)\n",
    "\n",
    "'''\n",
    "classifiers = [\n",
    "    (\"rf\", rf),\n",
    "    (\"svc\", svc)\n",
    "    #(\"xgb\", xgb)\n",
    "]\n",
    "\n",
    "mixclf = Pipeline([\n",
    "    (\"voting\", VotingClassifier(classifiers, voting=\"soft\"))\n",
    "])\n",
    "\n",
    "param_grid = dict(\n",
    "    #voting__weights=combinations_on_off(len(classifiers))\n",
    "    voting__weights=[[5,3],[4.1,3],[4.2,3],[4.3,3],[4.4,3],[4.5,3],[4.6,3],[4.7,3],[4.8,3],[4.9,3],[4.1,2.8],[4.2,2.8],[4.3,2.8],[4.4,2.8],[4.5,2.8],[4.6,2.8],[4.7,2.8],[4.8,2.8],[4.9,2.8]]\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(mixclf, param_grid=param_grid, n_jobs=-1, verbose=10, scoring=\"neg_log_loss\")\n",
    "\n",
    "grid_search.fit(Features_train, labels_train)\n",
    "\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "for mean_score, params in zip(cv_results[\"mean_test_score\"], cv_results[\"params\"]):\n",
    "    print(params, mean_score)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "'''    \n",
    "#mixclf = VotingClassifier(estimators=[('rf', rf), ('svc', svc)], voting='soft', weights=[4.95, 2.91])\n",
    "mixclf = VotingClassifier(estimators=[('rf', rf), ('svc', svc),('gb',gb),('xgb',xgb)], voting='soft', weights=[4.94,2.9,1,2])\n",
    "\n",
    "mixclf.fit(Features_train, labels_train)\n",
    "labels_pred = mixclf.predict(Features_test)\n",
    "print(accuracy_score(labels_test, labels_pred))\n",
    "\n",
    "plt.matshow(confusion_matrix(labels_test, labels_pred))\n",
    "plt.title('Confusion matrix - Voting Classifier')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "print confusion_matrix(labels_test, labels_pred)\n",
    "\n",
    "#stats.describe(cross_val_score(mixclf, Features, labels, cv=5, scoring='accuracy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is the test data like?\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputting data\n",
    "Here is a quick snippet of code to write the data to disk, and then we'll talk how to upload to leaderboard.  I'll make the all zero prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop([\"label\"], axis =1)\n",
    "#test =test.reset_index()\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixclf.fit(Features, labels)\n",
    "test['label'] = mixclf.predict(test)\n",
    "test[['label']].to_csv('/tmp/TTT_fake_sub_trial28.csv', index=True, index_label = 'ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting our model output out of Eider and into Leaderboard\n",
    "Great. Now we have a dummie sample submission in Eider that we now need to export locally so that we may then upload to Leaderboard in the following steps:\n",
    "1. Within the Eider console top bar, select [Files](https://eider.corp.amazon.com/file)\n",
    "2. You should now see 'Files', 'TMP' and 'Exported notebooks' tabs. \n",
    "3. Select 'TMP' then select 'Connect to workspace'. You should now see any files from your last run of your workspace. If there was no 'Connect to workspace' option, your files from the last run should already be present. *Files in the 'TMP' should be considered temporary as they will expire after an hour's worth of idle time.*\n",
    "4. Go to the ```TTT_fake_sub.csv``` file and select Save\n",
    "5. This file will now be permanently saved to your Eider account and available for local download.\n",
    "6. Go to the 'Files' tab, and click 'download' to save it to your local machine.\n",
    "\n",
    "We now have our model's output .csv and are ready to upload to Leaderboard\n",
    "1. Search for your [Leaderboard instance](https://leaderboard.corp.amazon.com/tasks/292) and go to the 'Make a Submission' section\n",
    "2. Upload your local file and include your notebook version URL for tracking.\n",
    "3. Your score on the public leaderboard should now appear. \n",
    "\n",
    "The private leaderboard contains the vast majority of the data, and so your final rankings in this competition will be a bit of a surprise! Take care and avoid overfitting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
