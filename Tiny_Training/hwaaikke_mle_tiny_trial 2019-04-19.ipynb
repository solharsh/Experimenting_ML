{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('/Users/hwaaikke/mle/tiny')\n",
    "train = pd.read_csv(path/'data/TTT_train.csv', header=0)\n",
    "test = pd.read_csv(path/'data/TTT_test_features.csv', index_col = 'ID', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "isf = IsolationForest(contamination='auto', behaviour='new', n_jobs=-1)\n",
    "isf.fit(train.drop('label', axis=1), train['label'])\n",
    "y_train_outlier = isf.predict(train.drop('label', axis=1))\n",
    "train = train[np.where(y_train_outlier == 1, True, False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train.drop('label', axis=1), train[\"label\"].values, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model and Testing Accuracy on Validation data\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "parameters = {'penalty':['l2'], 'C': np.arange(0.05, 1.05, 0.05)}\n",
    "\n",
    "lr = LogisticRegression(n_jobs=-1, multi_class='auto', solver='lbfgs', class_weight='balanced', max_iter=10000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "clf = GridSearchCV(lr, parameters, cv=9)\n",
    "clf.fit(train.drop('label', axis=1), train['label'])\n",
    "\n",
    "mnb = MultinomialNB(alpha=0.1)\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_jobs=-1, n_neighbors=9)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, n_estimators=100, random_state=1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "svc = SVC(gamma='scale', decision_function_shape='ovo')\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_val_lr = lr.predict(X_val)\n",
    "print('Accuracy score: lr ', accuracy_score(y_val, y_val_lr))\n",
    "y_val_clf = clf.predict(X_val)\n",
    "print('Accuracy score: clf ', accuracy_score(y_val, y_val_clf))\n",
    "y_val_mnb = mnb.predict(X_val)\n",
    "print('Accuracy score: mnb ', accuracy_score(y_val, y_val_mnb))\n",
    "y_val_gnb = gnb.predict(X_val)\n",
    "print('Accuracy score: gnb ', accuracy_score(y_val, y_val_gnb))\n",
    "y_val_knn = knn.predict(X_val)\n",
    "print('Accuracy score: knn ', accuracy_score(y_val, y_val_knn))\n",
    "y_val_rf = rf.predict(X_val)\n",
    "print('Accuracy score: rf ', accuracy_score(y_val, y_val_rf))\n",
    "y_val_svc = svc.predict(X_val)\n",
    "print('Accuracy score: svc ', accuracy_score(y_val, y_val_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You can try running eider.experimental.pip_import('mlxtend') to import the library necessary to run the code below. There were some issues when I tried importing it, which is why I used a jupyter notebook instead of eider in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = train.drop('label', axis=1).values\n",
    "y_train_all = train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingCVClassifier, StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, RidgeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb = xgb.XGBClassifier(verbosity=1,\n",
    "                        n_jobs=-1,\n",
    "                        objective='multi:softprob', \n",
    "                        n_estimators=500,\n",
    "                        max_depth=3)\n",
    "\n",
    "params = {'meta-logisticregression__C': [0.001, 0.01, 0.1, 1, 10.0, 100]}\n",
    "\n",
    "sc = StackingClassifier(\n",
    "    classifiers=[\n",
    "        LogisticRegression(penalty='l2', n_jobs=-1, multi_class='auto', solver='lbfgs', max_iter=10000),\n",
    "        RandomForestClassifier(n_estimators=500, n_jobs=-1),\n",
    "        SGDClassifier(loss='log', max_iter=1000, tol=1e-3)\n",
    "    ],\n",
    "    verbose=1,\n",
    "    use_probas=True,\n",
    "    meta_classifier=LogisticRegression(penalty='l2', n_jobs=-1, multi_class='auto', solver='lbfgs', max_iter=10000)\n",
    ")\n",
    "\n",
    "sc.fit(X_train_all, y_train_all)\n",
    "\n",
    "y_val_sc = sc.predict(X_val)\n",
    "print('Accuracy score: sc ', accuracy_score(y_val, y_val_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slight param tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=sc, \n",
    "                    param_grid=params, \n",
    "                    cv=4)\n",
    "grid.fit(X_train_all, y_train_all)\n",
    "\n",
    "y_val_grid = grid.predict(X_val)\n",
    "print('Accuracy score: grid ', accuracy_score(y_val, y_val_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_selection.cross_val_score(sc, train.drop('label', axis=1).values, train['label'].values, cv=4, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Submission__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = sc.predict(test)\n",
    "result = test.reset_index()[['ID']].copy()\n",
    "result['label'] = y_test_pred\n",
    "\n",
    "result.to_csv(path_or_buf='/Users/hwaaikke/mle/tiny/hwaaikke_mle_tiny_submission.csv', encoding='utf-8', index=False, header=['ID', 'label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
